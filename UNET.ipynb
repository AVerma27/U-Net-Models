{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AVerma27/U-Net-Models/blob/main/UNET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVO3sKYdj0Oz"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OB-i2V8upwQ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1708cf8a-098a-474d-e531-0f000899248b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PWSUPTUjr8L"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np \n",
        "import os\n",
        "import glob\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "\n",
        "Sky = [128,128,128]\n",
        "Building = [128,0,0]\n",
        "Pole = [192,192,128]\n",
        "Road = [128,64,128]\n",
        "Pavement = [60,40,222]\n",
        "Tree = [128,128,0]\n",
        "SignSymbol = [192,128,128]\n",
        "Fence = [64,64,128]\n",
        "Car = [64,0,128]\n",
        "Pedestrian = [64,64,0]\n",
        "Bicyclist = [0,128,192]\n",
        "Unlabelled = [0,0,0]\n",
        "\n",
        "COLOR_DICT = np.array([Sky, Building, Pole, Road, Pavement,\n",
        "                          Tree, SignSymbol, Fence, Car, Pedestrian, Bicyclist, Unlabelled])\n",
        "\n",
        "\n",
        "def adjustData(img,mask,flag_multi_class,num_class):\n",
        "    if(flag_multi_class):\n",
        "        img = img / 255\n",
        "        mask = mask[:,:,:,0] if(len(mask.shape) == 4) else mask[:,:,0]\n",
        "        new_mask = np.zeros(mask.shape + (num_class,))\n",
        "        for i in range(num_class):\n",
        "            #for one pixel in the image, find the class in mask and convert it into one-hot vector\n",
        "            #index = np.where(mask == i)\n",
        "            #index_mask = (index[0],index[1],index[2],np.zeros(len(index[0]),dtype = np.int64) + i) if (len(mask.shape) == 4) else (index[0],index[1],np.zeros(len(index[0]),dtype = np.int64) + i)\n",
        "            #new_mask[index_mask] = 1\n",
        "            new_mask[mask == i,i] = 1\n",
        "        new_mask = np.reshape(new_mask,(new_mask.shape[0],new_mask.shape[1]*new_mask.shape[2],new_mask.shape[3])) if flag_multi_class else np.reshape(new_mask,(new_mask.shape[0]*new_mask.shape[1],new_mask.shape[2]))\n",
        "        mask = new_mask\n",
        "    elif(np.max(img) > 1):\n",
        "        img = img / 255\n",
        "        mask = mask /255\n",
        "        mask[mask > 0.5] = 1\n",
        "        mask[mask <= 0.5] = 0\n",
        "    return (img,mask)\n",
        "\n",
        "\n",
        "\n",
        "def trainGenerator(batch_size,train_path,image_folder,mask_folder,aug_dict,image_color_mode = \"grayscale\",\n",
        "                    mask_color_mode = \"grayscale\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n",
        "                    flag_multi_class = False,num_class = 2,save_to_dir = None,target_size = (256,256),seed = 1):\n",
        "    '''\n",
        "    can generate image and mask at the same time\n",
        "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
        "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
        "    '''\n",
        "    image_datagen = ImageDataGenerator(**aug_dict)\n",
        "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        classes = [image_folder],\n",
        "        class_mode = None,\n",
        "        color_mode = image_color_mode,\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "        save_to_dir = save_to_dir,\n",
        "        save_prefix  = image_save_prefix,\n",
        "        seed = seed)\n",
        "    mask_generator = mask_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        classes = [mask_folder],\n",
        "        class_mode = None,\n",
        "        color_mode = mask_color_mode,\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "        save_to_dir = save_to_dir,\n",
        "        save_prefix  = mask_save_prefix,\n",
        "        seed = seed)\n",
        "    train_generator = zip(image_generator, mask_generator)\n",
        "    for (img,mask) in train_generator:\n",
        "        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n",
        "        yield (img,mask)\n",
        "\n",
        "\n",
        "\n",
        "def testGenerator(test_path,num_image = 30,target_size = (256,256),flag_multi_class = False,as_gray = True):\n",
        "    for i in range(num_image):\n",
        "        img = io.imread(os.path.join(test_path,\"%d.png\"%i),as_gray = as_gray)\n",
        "        img = img / 255\n",
        "        img = trans.resize(img,target_size)\n",
        "        img = np.reshape(img,img.shape+(1,)) if (not flag_multi_class) else img\n",
        "        img = np.reshape(img,(1,)+img.shape)\n",
        "        yield img\n",
        "\n",
        "\n",
        "def geneTrainNpy(image_path,mask_path,flag_multi_class = False,num_class = 2,image_prefix = \"image\",mask_prefix = \"mask\",image_as_gray = True,mask_as_gray = True):\n",
        "    image_name_arr = glob.glob(os.path.join(image_path,\"%s*.png\"%image_prefix))\n",
        "    image_arr = []\n",
        "    mask_arr = []\n",
        "    for index,item in enumerate(image_name_arr):\n",
        "        img = io.imread(item,as_gray = image_as_gray)\n",
        "        img = np.reshape(img,img.shape + (1,)) if image_as_gray else img\n",
        "        mask = io.imread(item.replace(image_path,mask_path).replace(image_prefix,mask_prefix),as_gray = mask_as_gray)\n",
        "        mask = np.reshape(mask,mask.shape + (1,)) if mask_as_gray else mask\n",
        "        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n",
        "        image_arr.append(img)\n",
        "        mask_arr.append(mask)\n",
        "    image_arr = np.array(image_arr)\n",
        "    mask_arr = np.array(mask_arr)\n",
        "    return image_arr,mask_arr\n",
        "\n",
        "\n",
        "def labelVisualize(num_class,color_dict,img):\n",
        "    img = img[:,:,0] if len(img.shape) == 3 else img\n",
        "    img_out = np.zeros(img.shape + (3,))\n",
        "    for i in range(num_class):\n",
        "        img_out[img == i,:] = color_dict[i]\n",
        "    return img_out / 255\n",
        "\n",
        "\n",
        "\n",
        "def saveResult(save_path,npyfile,flag_multi_class = False,num_class = 2):\n",
        "    for i,item in enumerate(npyfile):\n",
        "        img = labelVisualize(num_class,COLOR_DICT,item) if flag_multi_class else item[:,:,0]\n",
        "        io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zx_Pm71j634"
      },
      "source": [
        "### DataPrepare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOrAarLTgFLu"
      },
      "source": [
        "**Data Augmentation**\n",
        "\n",
        "https://www.youtube.com/watch?v=ccdssX4rIh8\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wU6oA9r6j8ao"
      },
      "outputs": [],
      "source": [
        "data_gen_args = dict(rotation_range=0.2,\n",
        "                    width_shift_range=0.05,\n",
        "                    height_shift_range=0.05,\n",
        "                    shear_range=0.05,\n",
        "                    zoom_range=0.05,\n",
        "                    horizontal_flip=True,\n",
        "                    fill_mode='nearest')\n",
        "myGenerator = trainGenerator(20,'/content/drive/MyDrive/membrane - UNet/train','image','label',data_gen_args,save_to_dir = \"/content/drive/MyDrive/membrane - UNet/train/aug\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZQsTyPakEhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aa878e9-93b4-4dc5-d95d-5c16d0a82f73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 30 images belonging to 1 classes.\n",
            "Found 30 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "#you will see 60 transformed images and their masks in data/membrane/train/aug\n",
        "num_batch = 3\n",
        "for i,batch in enumerate(myGenerator):\n",
        "    if(i >= num_batch):\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEfMGEi2kehu"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9r2AQtM-Mym"
      },
      "source": [
        "## UNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtqxpmwFkKur"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import os\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as keras\n",
        "\n",
        "\n",
        "def unet(pretrained_weights = None,input_size = (256,256,1)):\n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "    merge6 = concatenate([drop4,up6], axis = 3)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "\n",
        "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "\n",
        "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "    merge8 = concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "\n",
        "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "    merge9 = concatenate([conv1,up9], axis = 3)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
        "\n",
        "    model = Model(inputs = inputs, outputs = conv10)\n",
        "    #model = Model()\n",
        "\n",
        "    \n",
        "     #model.compile(optimizer = tf.optimizers.Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "     #model.summary()\n",
        "    \n",
        "\n",
        "    if(pretrained_weights):\n",
        "    \tmodel.load_weights(pretrained_weights)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc0FNLFnsVNV"
      },
      "source": [
        "## Losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLSjtSCkEFr9"
      },
      "outputs": [],
      "source": [
        "# Dice similarity coefficient loss, brought to you by: https://github.com/nabsabraham/focal-tversky-unet\n",
        "from tensorflow import reduce_sum\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "\n",
        "def dsc(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = Flatten()(y_true)\n",
        "    y_pred_f = Flatten()(y_pred)\n",
        "    intersection = reduce_sum(y_true_f * y_pred_f)\n",
        "    score = (2. * intersection + smooth) / (reduce_sum(y_true_f) + reduce_sum(y_pred_f) + smooth)\n",
        "    return score\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    loss = 1 - dsc(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCDraYZysUjP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "2ddd6571-ccee-4db2-d8ef-dbf613fb01c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'from keras import backend as K \\n\\n# different loss functions\\ndef dice_coef(y_true, y_pred):\\n    smooth = 1.0  #0.0\\n    y_true_f = K.flatten(y_true)\\n    y_pred_f = K.flatten(y_pred)\\n    intersection = K.sum(y_true_f * y_pred_f)\\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\\n\\ndef jacard(y_true, y_pred):\\n\\n    y_true_f = K.flatten(y_true)\\n    y_pred_f = K.flatten(y_pred)\\n    intersection = K.sum ( y_true_f * y_pred_f)\\n    union = K.sum ( y_true_f + y_pred_f - y_true_f * y_pred_f)\\n\\n    return intersection/union\\n\\ndef dice_coef_loss(y_true,y_pred):\\n    return 1 - dice_coef(y_true,y_pred)\\n\\ndef iou_loss(y_true,y_pred):\\n    return 1 - jacard(y_true, y_pred)\\n    \\ndef tversky(y_true, y_pred):\\n    y_true_pos = K.flatten(y_true)\\n    y_pred_pos = K.flatten(y_pred)\\n    true_pos = K.sum(y_true_pos * y_pred_pos)\\n    false_neg = K.sum(y_true_pos * (1-y_pred_pos))\\n    false_pos = K.sum((1-y_true_pos)*y_pred_pos)\\n    alpha = 0.75\\n    smooth = 1\\n    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\\n\\n\\ndef tversky_loss(y_true, y_pred):\\n    return 1 - tversky(y_true,y_pred)\\n\\n\\ndef focal_tversky(y_true,y_pred):\\n    pt_1 = tversky(y_true, y_pred)\\n    gamma = 0.75\\n    return K.pow((1-pt_1), gamma)\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "'''from keras import backend as K \n",
        "\n",
        "# different loss functions\n",
        "def dice_coef(y_true, y_pred):\n",
        "    smooth = 1.0  #0.0\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def jacard(y_true, y_pred):\n",
        "\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum ( y_true_f * y_pred_f)\n",
        "    union = K.sum ( y_true_f + y_pred_f - y_true_f * y_pred_f)\n",
        "\n",
        "    return intersection/union\n",
        "\n",
        "def dice_coef_loss(y_true,y_pred):\n",
        "    return 1 - dice_coef(y_true,y_pred)\n",
        "\n",
        "def iou_loss(y_true,y_pred):\n",
        "    return 1 - jacard(y_true, y_pred)\n",
        "    \n",
        "def tversky(y_true, y_pred):\n",
        "    y_true_pos = K.flatten(y_true)\n",
        "    y_pred_pos = K.flatten(y_pred)\n",
        "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
        "    false_neg = K.sum(y_true_pos * (1-y_pred_pos))\n",
        "    false_pos = K.sum((1-y_true_pos)*y_pred_pos)\n",
        "    alpha = 0.75\n",
        "    smooth = 1\n",
        "    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n",
        "\n",
        "\n",
        "def tversky_loss(y_true, y_pred):\n",
        "    return 1 - tversky(y_true,y_pred)\n",
        "\n",
        "\n",
        "def focal_tversky(y_true,y_pred):\n",
        "    pt_1 = tversky(y_true, y_pred)\n",
        "    gamma = 0.75\n",
        "    return K.pow((1-pt_1), gamma)\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cC7XqeZIr8go"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K \n",
        "\n",
        "\n",
        "def jacard_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
        "\n",
        "\n",
        "def jacard_coef_loss(y_true, y_pred):\n",
        "    return -jacard_coef(y_true, y_pred)  # -1 ultiplied as we want to minimize this value as loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8yLq26sOpl6"
      },
      "source": [
        "## Train UNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAEfEgjfkz2U"
      },
      "outputs": [],
      "source": [
        "\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "\n",
        "data_gen_args = dict(rotation_range=0.2,\n",
        "                    width_shift_range=0.05,\n",
        "                    height_shift_range=0.05,\n",
        "                    shear_range=0.05,\n",
        "                    zoom_range=0.05,\n",
        "                    horizontal_flip=True,\n",
        "                    fill_mode='nearest')\n",
        "myGene = trainGenerator(2,\"/content/drive/MyDrive/membrane - UNet/train\",'image','label',data_gen_args,save_to_dir = None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFcT1oYssCLB"
      },
      "outputs": [],
      "source": [
        "model = unet()\n",
        "#metrics = ['accuracy', dice_loss, jacard, iou_loss, tversky_loss,focal_tversky]\n",
        "#loss = [jacard_coef_loss], metrics = [jacard_coef]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjUs25rEr6xV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8776b98-5fbb-4f73-84fe-a5c6b5ec54be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 256, 256, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 256, 256, 64  640         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 256, 256, 64  36928       ['conv2d[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 128, 128, 64  0           ['conv2d_1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 128, 128, 12  73856       ['max_pooling2d[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 128, 128, 12  147584      ['conv2d_2[0][0]']               \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0          ['conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 64, 64, 256)  295168      ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 64, 64, 256)  590080      ['conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0          ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 32, 32, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 32, 32, 512)  2359808     ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 32, 32, 512)  0           ['conv2d_7[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0          ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 1024  4719616     ['max_pooling2d_3[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 1024  9438208     ['conv2d_8[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 16, 16, 1024  0           ['conv2d_9[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2D)   (None, 32, 32, 1024  0           ['dropout_1[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 32, 32, 512)  2097664     ['up_sampling2d[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 32, 32, 1024  0           ['dropout[0][0]',                \n",
            "                                )                                 'conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 32, 32, 512)  4719104     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_11[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 512)  0          ['conv2d_12[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 64, 64, 256)  524544      ['up_sampling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 64, 64, 512)  0           ['conv2d_5[0][0]',               \n",
            "                                                                  'conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 64, 64, 256)  1179904     ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 25  0          ['conv2d_15[0][0]']              \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 128, 128, 12  131200      ['up_sampling2d_2[0][0]']        \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 128, 128, 25  0           ['conv2d_3[0][0]',               \n",
            "                                6)                                'conv2d_16[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 128, 128, 12  295040      ['concatenate_2[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_17[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 12  0          ['conv2d_18[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 256, 256, 64  32832       ['up_sampling2d_3[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 256, 256, 12  0           ['conv2d_1[0][0]',               \n",
            "                                8)                                'conv2d_19[0][0]']              \n",
            "                                                                                                  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " conv2d_20 (Conv2D)             (None, 256, 256, 64  73792       ['concatenate_3[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_20[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 256, 256, 2)  1154        ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 256, 256, 1)  3           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31,031,685\n",
            "Trainable params: 31,031,685\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#model.compile(optimizer = tf.optimizers.Adam(lr = 1e-4), loss =\"binary_crossentropy\", metrics =metrics) \n",
        "model.compile(optimizer = tf.optimizers.Adam(lr = 1e-4), loss = [jacard_coef_loss], metrics = [jacard_coef,'accuracy'])   \n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsAxYwGMsF_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25babec5-a3f4-4617-aa78-a928eb4acfca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 30 images belonging to 1 classes.\n",
            "Found 30 images belonging to 1 classes.\n",
            "Epoch 1/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.6111 - jacard_coef: 0.6111 - accuracy: 0.7526\n",
            "Epoch 1: loss improved from inf to -0.61115, saving model to unet_membrane.hdf5\n",
            "20/20 [==============================] - 21s 220ms/step - loss: -0.6111 - jacard_coef: 0.6111 - accuracy: 0.7526\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7789 - jacard_coef: 0.7789 - accuracy: 0.7794\n",
            "Epoch 2: loss improved from -0.61115 to -0.77894, saving model to unet_membrane.hdf5\n",
            "20/20 [==============================] - 4s 216ms/step - loss: -0.7789 - jacard_coef: 0.7789 - accuracy: 0.7794\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7825 - jacard_coef: 0.7825 - accuracy: 0.7825\n",
            "Epoch 3: loss improved from -0.77894 to -0.78249, saving model to unet_membrane.hdf5\n",
            "20/20 [==============================] - 4s 216ms/step - loss: -0.7825 - jacard_coef: 0.7825 - accuracy: 0.7825\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7836 - jacard_coef: 0.7836 - accuracy: 0.7836\n",
            "Epoch 4: loss improved from -0.78249 to -0.78357, saving model to unet_membrane.hdf5\n",
            "20/20 [==============================] - 4s 217ms/step - loss: -0.7836 - jacard_coef: 0.7836 - accuracy: 0.7836\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7789 - jacard_coef: 0.7789 - accuracy: 0.7789\n",
            "Epoch 5: loss did not improve from -0.78357\n",
            "20/20 [==============================] - 3s 155ms/step - loss: -0.7789 - jacard_coef: 0.7789 - accuracy: 0.7789\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7805 - jacard_coef: 0.7805 - accuracy: 0.7805\n",
            "Epoch 6: loss did not improve from -0.78357\n",
            "20/20 [==============================] - 3s 156ms/step - loss: -0.7805 - jacard_coef: 0.7805 - accuracy: 0.7805\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7810 - jacard_coef: 0.7810 - accuracy: 0.7810\n",
            "Epoch 7: loss did not improve from -0.78357\n",
            "20/20 [==============================] - 3s 156ms/step - loss: -0.7810 - jacard_coef: 0.7810 - accuracy: 0.7810\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7834 - jacard_coef: 0.7834 - accuracy: 0.7834\n",
            "Epoch 8: loss did not improve from -0.78357\n",
            "20/20 [==============================] - 3s 156ms/step - loss: -0.7834 - jacard_coef: 0.7834 - accuracy: 0.7834\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7813 - jacard_coef: 0.7813 - accuracy: 0.7813\n",
            "Epoch 9: loss did not improve from -0.78357\n",
            "20/20 [==============================] - 3s 156ms/step - loss: -0.7813 - jacard_coef: 0.7813 - accuracy: 0.7813\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7792 - jacard_coef: 0.7792 - accuracy: 0.7792\n",
            "Epoch 10: loss did not improve from -0.78357\n",
            "20/20 [==============================] - 3s 156ms/step - loss: -0.7792 - jacard_coef: 0.7792 - accuracy: 0.7792\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7826 - jacard_coef: 0.7826 - accuracy: 0.7826\n",
            "Epoch 11: loss did not improve from -0.78357\n",
            "20/20 [==============================] - 3s 157ms/step - loss: -0.7826 - jacard_coef: 0.7826 - accuracy: 0.7826\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7819 - jacard_coef: 0.7819 - accuracy: 0.7819\n",
            "Epoch 12: loss did not improve from -0.78357\n",
            "20/20 [==============================] - 3s 158ms/step - loss: -0.7819 - jacard_coef: 0.7819 - accuracy: 0.7819\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7785 - jacard_coef: 0.7785 - accuracy: 0.7785\n",
            "Epoch 13: loss did not improve from -0.78357\n",
            "20/20 [==============================] - 3s 158ms/step - loss: -0.7785 - jacard_coef: 0.7785 - accuracy: 0.7785\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7820 - jacard_coef: 0.7820 - accuracy: 0.7820\n",
            "Epoch 14: loss did not improve from -0.78357\n",
            "20/20 [==============================] - 3s 159ms/step - loss: -0.7820 - jacard_coef: 0.7820 - accuracy: 0.7820\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7831 - jacard_coef: 0.7831 - accuracy: 0.7831\n",
            "Epoch 15: loss did not improve from -0.78357\n",
            "20/20 [==============================] - 3s 159ms/step - loss: -0.7831 - jacard_coef: 0.7831 - accuracy: 0.7831\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7809 - jacard_coef: 0.7809 - accuracy: 0.7809\n",
            "Epoch 16: loss did not improve from -0.78357\n",
            "20/20 [==============================] - 3s 160ms/step - loss: -0.7809 - jacard_coef: 0.7809 - accuracy: 0.7809\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7803 - jacard_coef: 0.7803 - accuracy: 0.7803\n",
            "Epoch 17: loss did not improve from -0.78357\n",
            "20/20 [==============================] - 3s 160ms/step - loss: -0.7803 - jacard_coef: 0.7803 - accuracy: 0.7803\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7812 - jacard_coef: 0.7812 - accuracy: 0.7812\n",
            "Epoch 18: loss did not improve from -0.78357\n",
            "20/20 [==============================] - 3s 160ms/step - loss: -0.7812 - jacard_coef: 0.7812 - accuracy: 0.7812\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7784 - jacard_coef: 0.7784 - accuracy: 0.7784\n",
            "Epoch 19: loss did not improve from -0.78357\n",
            "20/20 [==============================] - 3s 160ms/step - loss: -0.7784 - jacard_coef: 0.7784 - accuracy: 0.7784\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7847 - jacard_coef: 0.7847 - accuracy: 0.7847\n",
            "Epoch 20: loss improved from -0.78357 to -0.78466, saving model to unet_membrane.hdf5\n",
            "20/20 [==============================] - 4s 224ms/step - loss: -0.7847 - jacard_coef: 0.7847 - accuracy: 0.7847\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7814 - jacard_coef: 0.7814 - accuracy: 0.7814\n",
            "Epoch 21: loss did not improve from -0.78466\n",
            "20/20 [==============================] - 3s 161ms/step - loss: -0.7814 - jacard_coef: 0.7814 - accuracy: 0.7814\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7816 - jacard_coef: 0.7816 - accuracy: 0.7816\n",
            "Epoch 22: loss did not improve from -0.78466\n",
            "20/20 [==============================] - 3s 162ms/step - loss: -0.7816 - jacard_coef: 0.7816 - accuracy: 0.7816\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7851 - jacard_coef: 0.7851 - accuracy: 0.7851\n",
            "Epoch 23: loss improved from -0.78466 to -0.78513, saving model to unet_membrane.hdf5\n",
            "20/20 [==============================] - 4s 224ms/step - loss: -0.7851 - jacard_coef: 0.7851 - accuracy: 0.7851\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7779 - jacard_coef: 0.7779 - accuracy: 0.7779\n",
            "Epoch 24: loss did not improve from -0.78513\n",
            "20/20 [==============================] - 3s 163ms/step - loss: -0.7779 - jacard_coef: 0.7779 - accuracy: 0.7779\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7803 - jacard_coef: 0.7803 - accuracy: 0.7803\n",
            "Epoch 25: loss did not improve from -0.78513\n",
            "20/20 [==============================] - 3s 163ms/step - loss: -0.7803 - jacard_coef: 0.7803 - accuracy: 0.7803\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7840 - jacard_coef: 0.7840 - accuracy: 0.7840\n",
            "Epoch 26: loss did not improve from -0.78513\n",
            "20/20 [==============================] - 3s 164ms/step - loss: -0.7840 - jacard_coef: 0.7840 - accuracy: 0.7840\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7790 - jacard_coef: 0.7790 - accuracy: 0.7790\n",
            "Epoch 27: loss did not improve from -0.78513\n",
            "20/20 [==============================] - 3s 164ms/step - loss: -0.7790 - jacard_coef: 0.7790 - accuracy: 0.7790\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7833 - jacard_coef: 0.7833 - accuracy: 0.7833\n",
            "Epoch 28: loss did not improve from -0.78513\n",
            "20/20 [==============================] - 3s 163ms/step - loss: -0.7833 - jacard_coef: 0.7833 - accuracy: 0.7833\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7814 - jacard_coef: 0.7814 - accuracy: 0.7814\n",
            "Epoch 29: loss did not improve from -0.78513\n",
            "20/20 [==============================] - 3s 162ms/step - loss: -0.7814 - jacard_coef: 0.7814 - accuracy: 0.7814\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7803 - jacard_coef: 0.7803 - accuracy: 0.7803\n",
            "Epoch 30: loss did not improve from -0.78513\n",
            "20/20 [==============================] - 3s 164ms/step - loss: -0.7803 - jacard_coef: 0.7803 - accuracy: 0.7803\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7819 - jacard_coef: 0.7819 - accuracy: 0.7819\n",
            "Epoch 31: loss did not improve from -0.78513\n",
            "20/20 [==============================] - 3s 174ms/step - loss: -0.7819 - jacard_coef: 0.7819 - accuracy: 0.7819\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7818 - jacard_coef: 0.7818 - accuracy: 0.7818\n",
            "Epoch 32: loss did not improve from -0.78513\n",
            "20/20 [==============================] - 4s 176ms/step - loss: -0.7818 - jacard_coef: 0.7818 - accuracy: 0.7818\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7825 - jacard_coef: 0.7825 - accuracy: 0.7825\n",
            "Epoch 33: loss did not improve from -0.78513\n",
            "20/20 [==============================] - 3s 166ms/step - loss: -0.7825 - jacard_coef: 0.7825 - accuracy: 0.7825\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7819 - jacard_coef: 0.7819 - accuracy: 0.7819\n",
            "Epoch 34: loss did not improve from -0.78513\n",
            "20/20 [==============================] - 3s 165ms/step - loss: -0.7819 - jacard_coef: 0.7819 - accuracy: 0.7819\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7820 - jacard_coef: 0.7820 - accuracy: 0.7820\n",
            "Epoch 35: loss did not improve from -0.78513\n",
            "20/20 [==============================] - 3s 166ms/step - loss: -0.7820 - jacard_coef: 0.7820 - accuracy: 0.7820\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7820 - jacard_coef: 0.7820 - accuracy: 0.7820\n",
            "Epoch 36: loss did not improve from -0.78513\n",
            "20/20 [==============================] - 3s 166ms/step - loss: -0.7820 - jacard_coef: 0.7820 - accuracy: 0.7820\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7804 - jacard_coef: 0.7804 - accuracy: 0.7804\n",
            "Epoch 37: loss did not improve from -0.78513\n",
            "20/20 [==============================] - 3s 166ms/step - loss: -0.7804 - jacard_coef: 0.7804 - accuracy: 0.7804\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7814 - jacard_coef: 0.7814 - accuracy: 0.7814\n",
            "Epoch 38: loss did not improve from -0.78513\n",
            "20/20 [==============================] - 3s 167ms/step - loss: -0.7814 - jacard_coef: 0.7814 - accuracy: 0.7814\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7855 - jacard_coef: 0.7855 - accuracy: 0.7855\n",
            "Epoch 39: loss improved from -0.78513 to -0.78555, saving model to unet_membrane.hdf5\n",
            "20/20 [==============================] - 4s 227ms/step - loss: -0.7855 - jacard_coef: 0.7855 - accuracy: 0.7855\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7810 - jacard_coef: 0.7810 - accuracy: 0.7810\n",
            "Epoch 40: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 167ms/step - loss: -0.7810 - jacard_coef: 0.7810 - accuracy: 0.7810\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7805 - jacard_coef: 0.7805 - accuracy: 0.7805\n",
            "Epoch 41: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7805 - jacard_coef: 0.7805 - accuracy: 0.7805\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7791 - jacard_coef: 0.7791 - accuracy: 0.7791\n",
            "Epoch 42: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7791 - jacard_coef: 0.7791 - accuracy: 0.7791\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7831 - jacard_coef: 0.7831 - accuracy: 0.7831\n",
            "Epoch 43: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 169ms/step - loss: -0.7831 - jacard_coef: 0.7831 - accuracy: 0.7831\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7767 - jacard_coef: 0.7767 - accuracy: 0.7767\n",
            "Epoch 44: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 170ms/step - loss: -0.7767 - jacard_coef: 0.7767 - accuracy: 0.7767\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7854 - jacard_coef: 0.7854 - accuracy: 0.7854\n",
            "Epoch 45: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 170ms/step - loss: -0.7854 - jacard_coef: 0.7854 - accuracy: 0.7854\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7803 - jacard_coef: 0.7803 - accuracy: 0.7803\n",
            "Epoch 46: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 170ms/step - loss: -0.7803 - jacard_coef: 0.7803 - accuracy: 0.7803\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7855 - jacard_coef: 0.7855 - accuracy: 0.7855\n",
            "Epoch 47: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 169ms/step - loss: -0.7855 - jacard_coef: 0.7855 - accuracy: 0.7855\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7803 - jacard_coef: 0.7803 - accuracy: 0.7803\n",
            "Epoch 48: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 169ms/step - loss: -0.7803 - jacard_coef: 0.7803 - accuracy: 0.7803\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7803 - jacard_coef: 0.7803 - accuracy: 0.7803\n",
            "Epoch 49: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7803 - jacard_coef: 0.7803 - accuracy: 0.7803\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7780 - jacard_coef: 0.7780 - accuracy: 0.7780\n",
            "Epoch 50: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7780 - jacard_coef: 0.7780 - accuracy: 0.7780\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7839 - jacard_coef: 0.7839 - accuracy: 0.7839\n",
            "Epoch 51: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7839 - jacard_coef: 0.7839 - accuracy: 0.7839\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7784 - jacard_coef: 0.7784 - accuracy: 0.7784\n",
            "Epoch 52: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 167ms/step - loss: -0.7784 - jacard_coef: 0.7784 - accuracy: 0.7784\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7855 - jacard_coef: 0.7855 - accuracy: 0.7855\n",
            "Epoch 53: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 167ms/step - loss: -0.7855 - jacard_coef: 0.7855 - accuracy: 0.7855\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7795 - jacard_coef: 0.7795 - accuracy: 0.7795\n",
            "Epoch 54: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 175ms/step - loss: -0.7795 - jacard_coef: 0.7795 - accuracy: 0.7795\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7821 - jacard_coef: 0.7821 - accuracy: 0.7821\n",
            "Epoch 55: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 167ms/step - loss: -0.7821 - jacard_coef: 0.7821 - accuracy: 0.7821\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7811 - jacard_coef: 0.7811 - accuracy: 0.7811\n",
            "Epoch 56: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 167ms/step - loss: -0.7811 - jacard_coef: 0.7811 - accuracy: 0.7811\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7811 - jacard_coef: 0.7811 - accuracy: 0.7811\n",
            "Epoch 57: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7811 - jacard_coef: 0.7811 - accuracy: 0.7811\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7822 - jacard_coef: 0.7822 - accuracy: 0.7822\n",
            "Epoch 58: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7822 - jacard_coef: 0.7822 - accuracy: 0.7822\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7795 - jacard_coef: 0.7795 - accuracy: 0.7795\n",
            "Epoch 59: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7795 - jacard_coef: 0.7795 - accuracy: 0.7795\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7813 - jacard_coef: 0.7813 - accuracy: 0.7813\n",
            "Epoch 60: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 167ms/step - loss: -0.7813 - jacard_coef: 0.7813 - accuracy: 0.7813\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7812 - jacard_coef: 0.7812 - accuracy: 0.7812\n",
            "Epoch 61: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7812 - jacard_coef: 0.7812 - accuracy: 0.7812\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7809 - jacard_coef: 0.7809 - accuracy: 0.7809\n",
            "Epoch 62: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7809 - jacard_coef: 0.7809 - accuracy: 0.7809\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7850 - jacard_coef: 0.7850 - accuracy: 0.7850\n",
            "Epoch 63: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7850 - jacard_coef: 0.7850 - accuracy: 0.7850\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7837 - jacard_coef: 0.7837 - accuracy: 0.7837\n",
            "Epoch 64: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7837 - jacard_coef: 0.7837 - accuracy: 0.7837\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7776 - jacard_coef: 0.7776 - accuracy: 0.7776\n",
            "Epoch 65: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7776 - jacard_coef: 0.7776 - accuracy: 0.7776\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7829 - jacard_coef: 0.7829 - accuracy: 0.7829\n",
            "Epoch 66: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7829 - jacard_coef: 0.7829 - accuracy: 0.7829\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7837 - jacard_coef: 0.7837 - accuracy: 0.7837\n",
            "Epoch 67: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7837 - jacard_coef: 0.7837 - accuracy: 0.7837\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7767 - jacard_coef: 0.7767 - accuracy: 0.7767\n",
            "Epoch 68: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 169ms/step - loss: -0.7767 - jacard_coef: 0.7767 - accuracy: 0.7767\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7838 - jacard_coef: 0.7838 - accuracy: 0.7838\n",
            "Epoch 69: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 169ms/step - loss: -0.7838 - jacard_coef: 0.7838 - accuracy: 0.7838\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7799 - jacard_coef: 0.7799 - accuracy: 0.7799\n",
            "Epoch 70: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 169ms/step - loss: -0.7799 - jacard_coef: 0.7799 - accuracy: 0.7799\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7833 - jacard_coef: 0.7833 - accuracy: 0.7833\n",
            "Epoch 71: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7833 - jacard_coef: 0.7833 - accuracy: 0.7833\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7824 - jacard_coef: 0.7824 - accuracy: 0.7824\n",
            "Epoch 72: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 169ms/step - loss: -0.7824 - jacard_coef: 0.7824 - accuracy: 0.7824\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7800 - jacard_coef: 0.7800 - accuracy: 0.7800\n",
            "Epoch 73: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 169ms/step - loss: -0.7800 - jacard_coef: 0.7800 - accuracy: 0.7800\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7841 - jacard_coef: 0.7841 - accuracy: 0.7841\n",
            "Epoch 74: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 169ms/step - loss: -0.7841 - jacard_coef: 0.7841 - accuracy: 0.7841\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7813 - jacard_coef: 0.7813 - accuracy: 0.7813\n",
            "Epoch 75: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 169ms/step - loss: -0.7813 - jacard_coef: 0.7813 - accuracy: 0.7813\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7822 - jacard_coef: 0.7822 - accuracy: 0.7822\n",
            "Epoch 76: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7822 - jacard_coef: 0.7822 - accuracy: 0.7822\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7801 - jacard_coef: 0.7801 - accuracy: 0.7801\n",
            "Epoch 77: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 169ms/step - loss: -0.7801 - jacard_coef: 0.7801 - accuracy: 0.7801\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7820 - jacard_coef: 0.7820 - accuracy: 0.7820\n",
            "Epoch 78: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7820 - jacard_coef: 0.7820 - accuracy: 0.7820\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7820 - jacard_coef: 0.7820 - accuracy: 0.7820\n",
            "Epoch 79: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7820 - jacard_coef: 0.7820 - accuracy: 0.7820\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7834 - jacard_coef: 0.7834 - accuracy: 0.7834\n",
            "Epoch 80: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7834 - jacard_coef: 0.7834 - accuracy: 0.7834\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7794 - jacard_coef: 0.7794 - accuracy: 0.7794\n",
            "Epoch 81: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 167ms/step - loss: -0.7794 - jacard_coef: 0.7794 - accuracy: 0.7794\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7799 - jacard_coef: 0.7799 - accuracy: 0.7799\n",
            "Epoch 82: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7799 - jacard_coef: 0.7799 - accuracy: 0.7799\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7831 - jacard_coef: 0.7831 - accuracy: 0.7831\n",
            "Epoch 83: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 167ms/step - loss: -0.7831 - jacard_coef: 0.7831 - accuracy: 0.7831\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7825 - jacard_coef: 0.7825 - accuracy: 0.7825\n",
            "Epoch 84: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7825 - jacard_coef: 0.7825 - accuracy: 0.7825\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7838 - jacard_coef: 0.7838 - accuracy: 0.7838\n",
            "Epoch 85: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7838 - jacard_coef: 0.7838 - accuracy: 0.7838\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7805 - jacard_coef: 0.7805 - accuracy: 0.7805\n",
            "Epoch 86: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7805 - jacard_coef: 0.7805 - accuracy: 0.7805\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7816 - jacard_coef: 0.7816 - accuracy: 0.7816\n",
            "Epoch 87: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7816 - jacard_coef: 0.7816 - accuracy: 0.7816\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7825 - jacard_coef: 0.7825 - accuracy: 0.7825\n",
            "Epoch 88: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7825 - jacard_coef: 0.7825 - accuracy: 0.7825\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7781 - jacard_coef: 0.7781 - accuracy: 0.7781\n",
            "Epoch 89: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7781 - jacard_coef: 0.7781 - accuracy: 0.7781\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7850 - jacard_coef: 0.7850 - accuracy: 0.7850\n",
            "Epoch 90: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7850 - jacard_coef: 0.7850 - accuracy: 0.7850\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7781 - jacard_coef: 0.7781 - accuracy: 0.7781\n",
            "Epoch 91: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 169ms/step - loss: -0.7781 - jacard_coef: 0.7781 - accuracy: 0.7781\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7821 - jacard_coef: 0.7821 - accuracy: 0.7821\n",
            "Epoch 92: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 169ms/step - loss: -0.7821 - jacard_coef: 0.7821 - accuracy: 0.7821\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7837 - jacard_coef: 0.7837 - accuracy: 0.7837\n",
            "Epoch 93: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 169ms/step - loss: -0.7837 - jacard_coef: 0.7837 - accuracy: 0.7837\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7806 - jacard_coef: 0.7806 - accuracy: 0.7806\n",
            "Epoch 94: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 169ms/step - loss: -0.7806 - jacard_coef: 0.7806 - accuracy: 0.7806\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7811 - jacard_coef: 0.7811 - accuracy: 0.7811\n",
            "Epoch 95: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 169ms/step - loss: -0.7811 - jacard_coef: 0.7811 - accuracy: 0.7811\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7819 - jacard_coef: 0.7819 - accuracy: 0.7819\n",
            "Epoch 96: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7819 - jacard_coef: 0.7819 - accuracy: 0.7819\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7805 - jacard_coef: 0.7805 - accuracy: 0.7805\n",
            "Epoch 97: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7805 - jacard_coef: 0.7805 - accuracy: 0.7805\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7846 - jacard_coef: 0.7846 - accuracy: 0.7846\n",
            "Epoch 98: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 169ms/step - loss: -0.7846 - jacard_coef: 0.7846 - accuracy: 0.7846\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7800 - jacard_coef: 0.7800 - accuracy: 0.7800\n",
            "Epoch 99: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 169ms/step - loss: -0.7800 - jacard_coef: 0.7800 - accuracy: 0.7800\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - ETA: 0s - loss: -0.7819 - jacard_coef: 0.7819 - accuracy: 0.7819\n",
            "Epoch 100: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 3s 168ms/step - loss: -0.7819 - jacard_coef: 0.7819 - accuracy: 0.7819\n"
          ]
        }
      ],
      "source": [
        "model_checkpoint = ModelCheckpoint('unet_membrane.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
        "epoch = 100\n",
        "history_jaccard = model.fit(myGene,steps_per_epoch=20,epochs=epoch,callbacks=[model_checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZAhl72iz7sD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "055c0b56-0cac-49ef-a3a7-d9ab697d472d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=tf.optimizers.Adam(lr = 1e-4), loss=bce_dice_loss, metrics=[dice_loss,'accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqBUtWEUz7fn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d258072-9fc7-48a0-cbbb-d71a55876fc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 91.5462 - dice_loss: 0.2838 - accuracy: 0.7804\n",
            "Epoch 1: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 6s 174ms/step - loss: 91.5462 - dice_loss: 0.2838 - accuracy: 0.7804\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.7569 - dice_loss: 0.2288 - accuracy: 0.7803\n",
            "Epoch 2: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 177ms/step - loss: 0.7569 - dice_loss: 0.2288 - accuracy: 0.7803\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.6417 - dice_loss: 0.1784 - accuracy: 0.7818\n",
            "Epoch 3: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 176ms/step - loss: 0.6417 - dice_loss: 0.1784 - accuracy: 0.7818\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.5970 - dice_loss: 0.1695 - accuracy: 0.7804\n",
            "Epoch 4: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 176ms/step - loss: 0.5970 - dice_loss: 0.1695 - accuracy: 0.7804\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.5599 - dice_loss: 0.1602 - accuracy: 0.7808\n",
            "Epoch 5: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 177ms/step - loss: 0.5599 - dice_loss: 0.1602 - accuracy: 0.7808\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.5321 - dice_loss: 0.1520 - accuracy: 0.7794\n",
            "Epoch 6: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 177ms/step - loss: 0.5321 - dice_loss: 0.1520 - accuracy: 0.7794\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.4913 - dice_loss: 0.1422 - accuracy: 0.7841\n",
            "Epoch 7: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 177ms/step - loss: 0.4913 - dice_loss: 0.1422 - accuracy: 0.7841\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.4819 - dice_loss: 0.1361 - accuracy: 0.7799\n",
            "Epoch 8: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 177ms/step - loss: 0.4819 - dice_loss: 0.1361 - accuracy: 0.7799\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.4670 - dice_loss: 0.1337 - accuracy: 0.7823\n",
            "Epoch 9: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 177ms/step - loss: 0.4670 - dice_loss: 0.1337 - accuracy: 0.7823\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.4657 - dice_loss: 0.1314 - accuracy: 0.7816\n",
            "Epoch 10: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.4657 - dice_loss: 0.1314 - accuracy: 0.7816\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.4642 - dice_loss: 0.1293 - accuracy: 0.7790\n",
            "Epoch 11: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 176ms/step - loss: 0.4642 - dice_loss: 0.1293 - accuracy: 0.7790\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.4561 - dice_loss: 0.1286 - accuracy: 0.7808\n",
            "Epoch 12: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.4561 - dice_loss: 0.1286 - accuracy: 0.7808\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.4510 - dice_loss: 0.1260 - accuracy: 0.8577\n",
            "Epoch 13: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 177ms/step - loss: 0.4510 - dice_loss: 0.1260 - accuracy: 0.8577\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.4438 - dice_loss: 0.1246 - accuracy: 0.8664\n",
            "Epoch 14: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 177ms/step - loss: 0.4438 - dice_loss: 0.1246 - accuracy: 0.8664\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.4475 - dice_loss: 0.1250 - accuracy: 0.8642\n",
            "Epoch 15: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.4475 - dice_loss: 0.1250 - accuracy: 0.8642\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.4256 - dice_loss: 0.1186 - accuracy: 0.8656\n",
            "Epoch 16: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.4256 - dice_loss: 0.1186 - accuracy: 0.8656\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.3945 - dice_loss: 0.1086 - accuracy: 0.8734\n",
            "Epoch 17: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 177ms/step - loss: 0.3945 - dice_loss: 0.1086 - accuracy: 0.8734\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.3827 - dice_loss: 0.1034 - accuracy: 0.8771\n",
            "Epoch 18: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 177ms/step - loss: 0.3827 - dice_loss: 0.1034 - accuracy: 0.8771\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.3813 - dice_loss: 0.1043 - accuracy: 0.8783\n",
            "Epoch 19: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.3813 - dice_loss: 0.1043 - accuracy: 0.8783\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.3647 - dice_loss: 0.0984 - accuracy: 0.8845\n",
            "Epoch 20: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 177ms/step - loss: 0.3647 - dice_loss: 0.0984 - accuracy: 0.8845\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.3586 - dice_loss: 0.0964 - accuracy: 0.8868\n",
            "Epoch 21: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 177ms/step - loss: 0.3586 - dice_loss: 0.0964 - accuracy: 0.8868\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.3601 - dice_loss: 0.0980 - accuracy: 0.8857\n",
            "Epoch 22: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 179ms/step - loss: 0.3601 - dice_loss: 0.0980 - accuracy: 0.8857\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.3585 - dice_loss: 0.0953 - accuracy: 0.8870\n",
            "Epoch 23: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 177ms/step - loss: 0.3585 - dice_loss: 0.0953 - accuracy: 0.8870\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.3329 - dice_loss: 0.0902 - accuracy: 0.8951\n",
            "Epoch 24: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 177ms/step - loss: 0.3329 - dice_loss: 0.0902 - accuracy: 0.8951\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.3343 - dice_loss: 0.0895 - accuracy: 0.8947\n",
            "Epoch 25: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.3343 - dice_loss: 0.0895 - accuracy: 0.8947\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.3326 - dice_loss: 0.0895 - accuracy: 0.8950\n",
            "Epoch 26: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 177ms/step - loss: 0.3326 - dice_loss: 0.0895 - accuracy: 0.8950\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.3187 - dice_loss: 0.0858 - accuracy: 0.8996\n",
            "Epoch 27: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.3187 - dice_loss: 0.0858 - accuracy: 0.8996\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.3333 - dice_loss: 0.0891 - accuracy: 0.8947\n",
            "Epoch 28: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.3333 - dice_loss: 0.0891 - accuracy: 0.8947\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.3149 - dice_loss: 0.0848 - accuracy: 0.9011\n",
            "Epoch 29: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 177ms/step - loss: 0.3149 - dice_loss: 0.0848 - accuracy: 0.9011\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.3164 - dice_loss: 0.0844 - accuracy: 0.9009\n",
            "Epoch 30: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.3164 - dice_loss: 0.0844 - accuracy: 0.9009\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.3186 - dice_loss: 0.0857 - accuracy: 0.8995\n",
            "Epoch 31: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 177ms/step - loss: 0.3186 - dice_loss: 0.0857 - accuracy: 0.8995\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.3082 - dice_loss: 0.0825 - accuracy: 0.9026\n",
            "Epoch 32: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.3082 - dice_loss: 0.0825 - accuracy: 0.9026\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.3048 - dice_loss: 0.0809 - accuracy: 0.9042\n",
            "Epoch 33: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.3048 - dice_loss: 0.0809 - accuracy: 0.9042\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.3069 - dice_loss: 0.0827 - accuracy: 0.9036\n",
            "Epoch 34: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 179ms/step - loss: 0.3069 - dice_loss: 0.0827 - accuracy: 0.9036\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2959 - dice_loss: 0.0793 - accuracy: 0.9065\n",
            "Epoch 35: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 179ms/step - loss: 0.2959 - dice_loss: 0.0793 - accuracy: 0.9065\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2911 - dice_loss: 0.0781 - accuracy: 0.9083\n",
            "Epoch 36: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 179ms/step - loss: 0.2911 - dice_loss: 0.0781 - accuracy: 0.9083\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2948 - dice_loss: 0.0780 - accuracy: 0.9077\n",
            "Epoch 37: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 180ms/step - loss: 0.2948 - dice_loss: 0.0780 - accuracy: 0.9077\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2979 - dice_loss: 0.0794 - accuracy: 0.9063\n",
            "Epoch 38: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2979 - dice_loss: 0.0794 - accuracy: 0.9063\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2879 - dice_loss: 0.0769 - accuracy: 0.9098\n",
            "Epoch 39: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2879 - dice_loss: 0.0769 - accuracy: 0.9098\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2866 - dice_loss: 0.0761 - accuracy: 0.9103\n",
            "Epoch 40: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2866 - dice_loss: 0.0761 - accuracy: 0.9103\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2935 - dice_loss: 0.0788 - accuracy: 0.9076\n",
            "Epoch 41: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 179ms/step - loss: 0.2935 - dice_loss: 0.0788 - accuracy: 0.9076\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2914 - dice_loss: 0.0776 - accuracy: 0.9086\n",
            "Epoch 42: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 179ms/step - loss: 0.2914 - dice_loss: 0.0776 - accuracy: 0.9086\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2847 - dice_loss: 0.0762 - accuracy: 0.9105\n",
            "Epoch 43: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2847 - dice_loss: 0.0762 - accuracy: 0.9105\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2803 - dice_loss: 0.0744 - accuracy: 0.9120\n",
            "Epoch 44: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 179ms/step - loss: 0.2803 - dice_loss: 0.0744 - accuracy: 0.9120\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2841 - dice_loss: 0.0757 - accuracy: 0.9106\n",
            "Epoch 45: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 179ms/step - loss: 0.2841 - dice_loss: 0.0757 - accuracy: 0.9106\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2797 - dice_loss: 0.0748 - accuracy: 0.9123\n",
            "Epoch 46: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2797 - dice_loss: 0.0748 - accuracy: 0.9123\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2768 - dice_loss: 0.0735 - accuracy: 0.9131\n",
            "Epoch 47: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 179ms/step - loss: 0.2768 - dice_loss: 0.0735 - accuracy: 0.9131\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2676 - dice_loss: 0.0713 - accuracy: 0.9164\n",
            "Epoch 48: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2676 - dice_loss: 0.0713 - accuracy: 0.9164\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2757 - dice_loss: 0.0732 - accuracy: 0.9134\n",
            "Epoch 49: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2757 - dice_loss: 0.0732 - accuracy: 0.9134\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2802 - dice_loss: 0.0751 - accuracy: 0.9125\n",
            "Epoch 50: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 179ms/step - loss: 0.2802 - dice_loss: 0.0751 - accuracy: 0.9125\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2678 - dice_loss: 0.0710 - accuracy: 0.9162\n",
            "Epoch 51: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 179ms/step - loss: 0.2678 - dice_loss: 0.0710 - accuracy: 0.9162\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2690 - dice_loss: 0.0712 - accuracy: 0.9155\n",
            "Epoch 52: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 179ms/step - loss: 0.2690 - dice_loss: 0.0712 - accuracy: 0.9155\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2655 - dice_loss: 0.0714 - accuracy: 0.9169\n",
            "Epoch 53: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2655 - dice_loss: 0.0714 - accuracy: 0.9169\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2666 - dice_loss: 0.0709 - accuracy: 0.9166\n",
            "Epoch 54: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 180ms/step - loss: 0.2666 - dice_loss: 0.0709 - accuracy: 0.9166\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2659 - dice_loss: 0.0703 - accuracy: 0.9166\n",
            "Epoch 55: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 180ms/step - loss: 0.2659 - dice_loss: 0.0703 - accuracy: 0.9166\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2654 - dice_loss: 0.0713 - accuracy: 0.9165\n",
            "Epoch 56: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 179ms/step - loss: 0.2654 - dice_loss: 0.0713 - accuracy: 0.9165\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2634 - dice_loss: 0.0699 - accuracy: 0.9174\n",
            "Epoch 57: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2634 - dice_loss: 0.0699 - accuracy: 0.9174\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2584 - dice_loss: 0.0689 - accuracy: 0.9188\n",
            "Epoch 58: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 179ms/step - loss: 0.2584 - dice_loss: 0.0689 - accuracy: 0.9188\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2622 - dice_loss: 0.0702 - accuracy: 0.9175\n",
            "Epoch 59: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2622 - dice_loss: 0.0702 - accuracy: 0.9175\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2623 - dice_loss: 0.0697 - accuracy: 0.9177\n",
            "Epoch 60: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2623 - dice_loss: 0.0697 - accuracy: 0.9177\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2563 - dice_loss: 0.0684 - accuracy: 0.9192\n",
            "Epoch 61: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2563 - dice_loss: 0.0684 - accuracy: 0.9192\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2566 - dice_loss: 0.0682 - accuracy: 0.9196\n",
            "Epoch 62: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2566 - dice_loss: 0.0682 - accuracy: 0.9196\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2508 - dice_loss: 0.0668 - accuracy: 0.9211\n",
            "Epoch 63: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 179ms/step - loss: 0.2508 - dice_loss: 0.0668 - accuracy: 0.9211\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2499 - dice_loss: 0.0666 - accuracy: 0.9215\n",
            "Epoch 64: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2499 - dice_loss: 0.0666 - accuracy: 0.9215\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2616 - dice_loss: 0.0696 - accuracy: 0.9180\n",
            "Epoch 65: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2616 - dice_loss: 0.0696 - accuracy: 0.9180\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2558 - dice_loss: 0.0683 - accuracy: 0.9197\n",
            "Epoch 66: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2558 - dice_loss: 0.0683 - accuracy: 0.9197\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2503 - dice_loss: 0.0667 - accuracy: 0.9213\n",
            "Epoch 67: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 177ms/step - loss: 0.2503 - dice_loss: 0.0667 - accuracy: 0.9213\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2518 - dice_loss: 0.0670 - accuracy: 0.9208\n",
            "Epoch 68: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2518 - dice_loss: 0.0670 - accuracy: 0.9208\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2448 - dice_loss: 0.0650 - accuracy: 0.9232\n",
            "Epoch 69: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2448 - dice_loss: 0.0650 - accuracy: 0.9232\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2574 - dice_loss: 0.0692 - accuracy: 0.9190\n",
            "Epoch 70: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2574 - dice_loss: 0.0692 - accuracy: 0.9190\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2489 - dice_loss: 0.0662 - accuracy: 0.9219\n",
            "Epoch 71: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2489 - dice_loss: 0.0662 - accuracy: 0.9219\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2480 - dice_loss: 0.0661 - accuracy: 0.9219\n",
            "Epoch 72: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2480 - dice_loss: 0.0661 - accuracy: 0.9219\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2511 - dice_loss: 0.0673 - accuracy: 0.9212\n",
            "Epoch 73: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2511 - dice_loss: 0.0673 - accuracy: 0.9212\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2450 - dice_loss: 0.0651 - accuracy: 0.9232\n",
            "Epoch 74: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2450 - dice_loss: 0.0651 - accuracy: 0.9232\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2482 - dice_loss: 0.0667 - accuracy: 0.9219\n",
            "Epoch 75: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2482 - dice_loss: 0.0667 - accuracy: 0.9219\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2455 - dice_loss: 0.0651 - accuracy: 0.9230\n",
            "Epoch 76: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2455 - dice_loss: 0.0651 - accuracy: 0.9230\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2445 - dice_loss: 0.0655 - accuracy: 0.9229\n",
            "Epoch 77: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2445 - dice_loss: 0.0655 - accuracy: 0.9229\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2447 - dice_loss: 0.0654 - accuracy: 0.9233\n",
            "Epoch 78: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2447 - dice_loss: 0.0654 - accuracy: 0.9233\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2427 - dice_loss: 0.0647 - accuracy: 0.9232\n",
            "Epoch 79: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2427 - dice_loss: 0.0647 - accuracy: 0.9232\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2380 - dice_loss: 0.0638 - accuracy: 0.9249\n",
            "Epoch 80: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2380 - dice_loss: 0.0638 - accuracy: 0.9249\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2381 - dice_loss: 0.0636 - accuracy: 0.9251\n",
            "Epoch 81: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2381 - dice_loss: 0.0636 - accuracy: 0.9251\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2357 - dice_loss: 0.0629 - accuracy: 0.9257\n",
            "Epoch 82: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2357 - dice_loss: 0.0629 - accuracy: 0.9257\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2408 - dice_loss: 0.0643 - accuracy: 0.9240\n",
            "Epoch 83: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2408 - dice_loss: 0.0643 - accuracy: 0.9240\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2368 - dice_loss: 0.0635 - accuracy: 0.9250\n",
            "Epoch 84: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2368 - dice_loss: 0.0635 - accuracy: 0.9250\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2344 - dice_loss: 0.0623 - accuracy: 0.9259\n",
            "Epoch 85: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 179ms/step - loss: 0.2344 - dice_loss: 0.0623 - accuracy: 0.9259\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2340 - dice_loss: 0.0623 - accuracy: 0.9264\n",
            "Epoch 86: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2340 - dice_loss: 0.0623 - accuracy: 0.9264\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2334 - dice_loss: 0.0627 - accuracy: 0.9263\n",
            "Epoch 87: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 179ms/step - loss: 0.2334 - dice_loss: 0.0627 - accuracy: 0.9263\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2369 - dice_loss: 0.0633 - accuracy: 0.9252\n",
            "Epoch 88: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2369 - dice_loss: 0.0633 - accuracy: 0.9252\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2350 - dice_loss: 0.0630 - accuracy: 0.9255\n",
            "Epoch 89: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2350 - dice_loss: 0.0630 - accuracy: 0.9255\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2365 - dice_loss: 0.0638 - accuracy: 0.9252\n",
            "Epoch 90: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2365 - dice_loss: 0.0638 - accuracy: 0.9252\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2304 - dice_loss: 0.0612 - accuracy: 0.9273\n",
            "Epoch 91: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2304 - dice_loss: 0.0612 - accuracy: 0.9273\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2316 - dice_loss: 0.0620 - accuracy: 0.9269\n",
            "Epoch 92: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2316 - dice_loss: 0.0620 - accuracy: 0.9269\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2279 - dice_loss: 0.0610 - accuracy: 0.9282\n",
            "Epoch 93: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2279 - dice_loss: 0.0610 - accuracy: 0.9282\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2285 - dice_loss: 0.0610 - accuracy: 0.9276\n",
            "Epoch 94: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2285 - dice_loss: 0.0610 - accuracy: 0.9276\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2252 - dice_loss: 0.0602 - accuracy: 0.9288\n",
            "Epoch 95: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2252 - dice_loss: 0.0602 - accuracy: 0.9288\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2229 - dice_loss: 0.0598 - accuracy: 0.9298\n",
            "Epoch 96: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2229 - dice_loss: 0.0598 - accuracy: 0.9298\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2283 - dice_loss: 0.0611 - accuracy: 0.9278\n",
            "Epoch 97: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2283 - dice_loss: 0.0611 - accuracy: 0.9278\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2262 - dice_loss: 0.0608 - accuracy: 0.9283\n",
            "Epoch 98: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 179ms/step - loss: 0.2262 - dice_loss: 0.0608 - accuracy: 0.9283\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2242 - dice_loss: 0.0603 - accuracy: 0.9292\n",
            "Epoch 99: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2242 - dice_loss: 0.0603 - accuracy: 0.9292\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2265 - dice_loss: 0.0605 - accuracy: 0.9282\n",
            "Epoch 100: loss did not improve from -0.78555\n",
            "20/20 [==============================] - 4s 178ms/step - loss: 0.2265 - dice_loss: 0.0605 - accuracy: 0.9282\n"
          ]
        }
      ],
      "source": [
        "history_dice = model.fit(myGene,steps_per_epoch=20,epochs=epoch,callbacks=[model_checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YJB2nON0N3A"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbY3qop6A71J"
      },
      "outputs": [],
      "source": [
        "testGene = testGenerator(\"/content/drive/MyDrive/membrane - UNet/test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZE3atfqKBaYX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3e82884-859d-40bb-a8bc-a00245e422d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30/30 [==============================] - 11s 329ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/0_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/1_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/2_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/3_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/4_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/5_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/6_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/7_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/8_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/9_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/10_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/11_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/12_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/13_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/14_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/15_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/16_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/17_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/18_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/19_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/20_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/21_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/22_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/23_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/24_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/25_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/26_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/27_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/28_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: /content/drive/MyDrive/membrane - UNet/test/29_predict.png is a low contrast image\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        }
      ],
      "source": [
        "model.load_weights(\"unet_membrane.hdf5\")\n",
        "\n",
        "results = model.predict_generator(testGene,30,verbose=1)\n",
        "saveResult(\"/content/drive/MyDrive/membrane - UNet/test\",results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i17QO_lyAi4s"
      },
      "source": [
        "### **Plots**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZUAbh3fo414"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pylab as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOwkhKJtB-_5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rytZ7KpeEMBU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "96bdf287-6521-4641-ffc2-9cc17e13c2f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"#accuracy vs dice_loss\\nplt.subplot(1,2,2)\\nplt.plot(history.history['accuracy'])\\n#plt.plot(history.history['epochs'])\\nplt.title('dice_loss vs dice_loss')\\nplt.ylabel('dice_loss')\\nplt.xlabel('accuracy')\\nplt.legend(['train', 'validation'], loc='upper left')\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "'''#accuracy vs dice_loss\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['accuracy'])\n",
        "#plt.plot(history.history['epochs'])\n",
        "plt.title('dice_loss vs dice_loss')\n",
        "plt.ylabel('dice_loss')\n",
        "plt.xlabel('accuracy')\n",
        "plt.legend(['train', 'validation'], loc='upper left')'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8CZz1h8E0mT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "d08e05d7-d3e4-4ef3-de11-670abe131314"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'epoch')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(20,5))\n",
        "#plt.subplot(1,2,1)\n",
        "#plt.plot(history_dice.history['epochs'])\n",
        "plt.plot(history_dice.history['dice_loss'],color = 'Red')\n",
        "plt.title('dice_loss vs epoch')\n",
        "plt.ylabel('dice_loss')\n",
        "plt.xlabel('epoch')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.figure(figsize=(20,5))\n",
        "#plt.subplot(1,2,1)\n",
        "#plt.plot(history_dice.history['epochs'])\n",
        "plt.plot(history_jaccard.history['jacard_coef'], color = 'Red')\n",
        "plt.title('Jaccard Coefficient vs epoch')\n",
        "plt.ylabel('jacard_coef')\n",
        "plt.xlabel('epoch')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "BGgqk6Z2bt7D",
        "outputId": "edda0391-d9b9-4808-df1c-edd09c264704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'epoch')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,5))\n",
        "#plt.subplot(1,2,1)\n",
        "#plt.plot(history_dice.history['epochs'])\n",
        "plt.plot(history_jaccard.history['accuracy'], color = 'Red')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "scKyzbVgbxWO",
        "outputId": "f71fd3bc-778d-4690-e98e-5b6fd9396732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'epoch')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zYIx9aGPi2u-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "UNET.ipynb",
      "provenance": [],
      "mount_file_id": "1WFHG8SW68goSnf7yfNduWyCRDhDX2w76",
      "authorship_tag": "ABX9TyPgoSC4UVLSsIPhW4BXE6gk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}